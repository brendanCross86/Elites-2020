{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 1, DEFINE THE METHODS USED TO GENERATE:\n",
    "1) THE FORMATTED DATA USED BY THE SANKEY GENERATOR\n",
    "2) The basic version of the sankey diagram for a given bias\n",
    "3) A wrapper to generate these sankey diagrams for target biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import floweaver as fw\n",
    "import ipysankeywidget\n",
    "import lxml.etree as ET\n",
    "from bs4 import BeautifulSoup\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "\n",
    "TOP_N = 10\n",
    "cutoff = 50\n",
    "biases = ['left extreme', 'left leaning', 'left', 'center', 'right leaning', 'right', 'right extreme', 'fake']\n",
    "palette = {'right': '#8F100B', 'right leaning': '#DB4742', 'center': '#CFDB00', 'left leaning': '#4495DB',\n",
    "           'left': '#0E538F', 'left extreme': '#082E4F', 'right extreme': '#4F0906', 'fake': '#282828'}\n",
    "bias_to_plot_biases = {**{b: [b] for b in biases}, **{'lefts': ['left', 'left leaning'], 'rights': ['right', 'right leaning'], 'fake_extreme_right': ['fake', 'right extreme']}}\n",
    "\n",
    "# DEFINE PATHS TO DATA EDIT IF NEEDED\n",
    "TOP_INFLUENCERS = '../data/influencers'\n",
    "USER_MAPS = '../data/maps/'\n",
    "AFFILIATION = '../data/affiliations'\n",
    "\n",
    "# also, ensure the output directory exists\n",
    "if not os.path.exists('./output'):\n",
    "    os.makedirs('./output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BEGIN DATA TRANSFORM SECTION\n",
    "\n",
    "Goal: Take in the top influencer data and create the dataframes for each bias type.\n",
    "\n",
    "NOTE: Please read the README to find out how to generate the necessary input data to this script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    biased_dfs = {}\n",
    "    user_by_bias = {}\n",
    "    # first we load the influencer data for each media type\n",
    "    for bias in biases:\n",
    "        #biased_dfs[bias] = pd.read_csv('data/top_influencers_{}.csv'.format(bias))\n",
    "        biased_dfs[bias] = pd.read_csv(os.path.join(TOP_INFLUENCERS, 'top_influencers_{}.csv'.format(bias)))\n",
    "\n",
    "        # Here we add back in @RealAlexJones, who was highly ranked in 2016 but whose account was removed before 2020\n",
    "        # the removal means it was not pulled into the top influencer dataframes we just loaded\n",
    "        if bias == 'fake': \n",
    "            biased_dfs['fake'] = pd.concat([biased_dfs['fake'], pd.DataFrame([{'user_id': 0, 'CI_2016': 0, 'CI_2020': 0, 'rank_2016': 2.0, \n",
    "                    'bias': 'fake', 'user_handle': 'RealAlexJones', 'verified': 1}])])\n",
    "        user_by_bias[bias] = biased_dfs[bias][(biased_dfs[bias].rank_2016 <= TOP_N)|(biased_dfs[bias].rank_2020 <= TOP_N)].user_handle.values\n",
    "\n",
    "    # concatenate the dataframes for each media type into one merged frame\n",
    "    merged = pd.concat([x for x in biased_dfs.values()])\n",
    "\n",
    "    # add missing data from 2020\n",
    "    merged = pd.concat([merged, pd.DataFrame([{'user_id': 0, 'CI_2016': 0, 'CI_2020': 0, 'rank_2016': 2.0, \n",
    "                    'bias': 'fake', 'user_handle': 'RealAlexJones', 'verified': 1}])])\n",
    "\n",
    "    # here we add 3 custom merged media types. These will display the rank transitions for pairs of media types\n",
    "    # which will make the final plot more compact\n",
    "    biased_dfs['fake_extreme_right'] = pd.concat([biased_dfs['right extreme'], biased_dfs['fake']])\n",
    "    biased_dfs['fake_extreme_right'].sort_values(by='rank_2016')\n",
    "    user_by_bias['fake_extreme_right'] = biased_dfs['fake_extreme_right'][(biased_dfs['fake_extreme_right'].rank_2016 <= TOP_N)|(biased_dfs['fake_extreme_right'].rank_2020 <= TOP_N)].user_handle.values\n",
    "\n",
    "    biased_dfs['lefts'] = pd.concat([biased_dfs['left'], biased_dfs['left leaning']])\n",
    "    user_by_bias['lefts'] = biased_dfs['lefts'][(biased_dfs['lefts'].rank_2016 <= TOP_N)|(biased_dfs['lefts'].rank_2020 <= TOP_N)].user_handle.values\n",
    "\n",
    "    biased_dfs['rights'] = pd.concat([biased_dfs['right'], biased_dfs['right leaning']])\n",
    "    user_by_bias['rights'] = biased_dfs['rights'][(biased_dfs['rights'].rank_2016 <= TOP_N)|(biased_dfs['rights'].rank_2020 <= TOP_N)].user_handle.values\n",
    "\n",
    "    # compute positions and change in position\n",
    "    merged['position_2016'] = np.ceil(np.log2((merged.rank_2016 + 1)))\n",
    "    merged.position_2016 = merged.position_2016.clip(upper=6)\n",
    "    merged.position_2016 = merged.position_2016.replace(np.nan, 6)\n",
    "    merged['position_2020'] = np.ceil(np.log2((merged.rank_2020 + 1)))\n",
    "    merged.position_2020 = merged.position_2020.clip(upper=6)\n",
    "    merged.position_2020 = merged.position_2020.replace(np.nan, 6)\n",
    "    merged['delta_position'] = merged.position_2016 - merged.position_2020\n",
    "    return merged, user_by_bias\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create a method called \"format_data\". This method will ingest the merged data produced in the load step as\n",
    "well as a set of biases to target and will produce a dataframe formatted for use in the sankey generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(top_merged, plot_biases):\n",
    "    user_to_best = {}\n",
    "    for i, row in top_merged.iterrows():\n",
    "        user = row['user_handle']\n",
    "        rank_2016 = row['rank_2016'] if not np.isnan(row['rank_2016']) else np.inf\n",
    "        rank_2020 = row['rank_2020'] if not np.isnan(row['rank_2020']) else np.inf\n",
    "        if user in user_to_best:\n",
    "            # check if we should update\n",
    "            if rank_2016 == user_to_best[user]['rank_2016']:\n",
    "                if row['bias'] in plot_biases:\n",
    "                    user_to_best[user]['rank_2016'] = rank_2016\n",
    "                    user_to_best[user]['bias_2016'] = row['bias']\n",
    "            elif rank_2016 < user_to_best[user]['rank_2016']:\n",
    "                user_to_best[user]['rank_2016'] = rank_2016\n",
    "                user_to_best[user]['bias_2016'] = row['bias']\n",
    "            \n",
    "            if rank_2020 == user_to_best[user]['rank_2020']:\n",
    "                if row['bias'] in plot_biases:\n",
    "                    user_to_best[user]['rank_2020'] = rank_2020\n",
    "                    user_to_best[user]['bias_2020'] = row['bias']\n",
    "            elif rank_2020 < user_to_best[user]['rank_2020']:\n",
    "                if row['bias'] in plot_biases:\n",
    "                    user_to_best[user]['rank_2020'] = rank_2020\n",
    "                    user_to_best[user]['bias_2020'] = row['bias']\n",
    "                if user_to_best[user]['rank_2020'] <= 10 and user_to_best[user]['bias_2020'] in plot_biases:\n",
    "                    continue\n",
    "                if user_to_best[user]['bias_2020'] == 'center' and user_to_best[user]['rank_2020'] <= 10:\n",
    "                    continue\n",
    "                user_to_best[user]['rank_2020'] = rank_2020\n",
    "                user_to_best[user]['bias_2020'] = row['bias']\n",
    "            else:\n",
    "                if user_to_best[user]['bias_2020'] not in plot_biases and rank_2020 <= 10 and row['bias'] in plot_biases:\n",
    "                    user_to_best[user]['rank_2020'] = rank_2020\n",
    "                    user_to_best[user]['bias_2020'] = row['bias']\n",
    "        else:\n",
    "            user_to_best[user] = {\n",
    "                'user_handle': user,\n",
    "                'rank_2016': rank_2016, \n",
    "                'bias_2016': row['bias'], \n",
    "                'rank_2020': rank_2020, \n",
    "                'bias_2020': row['bias']\n",
    "            }\n",
    "\n",
    "    new_merged = pd.DataFrame(list(user_to_best.values()))\n",
    "    rank_to_str = lambda rank: 'rank > {}'.format(cutoff) if (np.isnan(rank) or rank>cutoff) else str(int(rank))\n",
    "    new_merged['rank_2016_str'] = new_merged.rank_2016.map(rank_to_str)\n",
    "    new_merged['rank_2020_str'] = new_merged.rank_2020.map(rank_to_str)\n",
    "    return new_merged\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BEGIN SANKEY SECTION:\n",
    "\n",
    "GOAL: Generate the initial form of the sankey diagram, will contain all the information of each individual subplot\n",
    "      of figure 4, but will require a little prettifying in a post-processing step to be paper ready.\n",
    "\n",
    "NOTES: \n",
    "1) This method requires being run in a jupyter notebook due to the underlying package we use to create the sankey diagram\n",
    "   \"floweaver\". It produces a widget that is only rendered in the notebook. There is no way to convert the diagram \n",
    "   directly into an svg file, it must be rendered as a widget and saved as an svg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_intermediate_sankey(new_merged, bias):\n",
    "    rank_to_str = lambda rank: 'rank > {}'.format(cutoff) if (np.isnan(rank) or rank>cutoff) else str(int(rank))\n",
    "    rows = []\n",
    "    unique_r2016 = []\n",
    "    unique_r2020 = []\n",
    "    for index, (user, r2016, bias2016, r2020, bias2020, r2016_sr, r2020_str) in new_merged.iterrows():\n",
    "        if r2016 <= cutoff:\n",
    "            unique_r2016.append(r2016)\n",
    "        if r2020 <= cutoff:\n",
    "            unique_r2020.append(r2020)\n",
    "        rows.append({'source': user, 'target': r2020_str, 'type': bias2020, 'value': 1})\n",
    "\n",
    "    unique_r2016 = np.unique(unique_r2016)\n",
    "    unique_r2020 = np.unique(unique_r2020)\n",
    "        \n",
    "    flows = pd.DataFrame(rows)\n",
    "    size = dict(width=1600, height=1200)\n",
    "\n",
    "    nodes = {\n",
    "        'users': fw.ProcessGroup([x for x in new_merged.user_handle.unique()]),\n",
    "        '2020': fw.ProcessGroup([rank_to_str(rank) for rank in new_merged.rank_2020.unique()]),\n",
    "    }\n",
    "\n",
    "    ordered_users = list(new_merged.sort_values(by=['rank_2016', 'user_handle']).drop_duplicates('user_handle', keep='first').user_handle)\n",
    "    users_partition = fw.Partition.Simple('process', ordered_users)\n",
    "    sorted_rank_2020 = [rank_to_str(rank) for rank in np.sort(unique_r2020)]\n",
    "    rank_partition_2020 = fw.Partition.Simple('process', sorted_rank_2020)\n",
    "    nodes['users'].partition = users_partition\n",
    "    nodes['2020'].partition = rank_partition_2020\n",
    "\n",
    "    ordering = [\n",
    "        ['users'],\n",
    "        ['2020']\n",
    "    ]\n",
    "    bias_types = fw.Partition.Simple('type', biases)\n",
    "\n",
    "    bundles = [\n",
    "        fw.Bundle('users', '2020')\n",
    "    ]\n",
    "\n",
    "    # generate our figure svg\n",
    "    margins = dict(top=0, bottom=0, left=360, right=160)\n",
    "    sdd = fw.SankeyDefinition(nodes, bundles, ordering, flow_partition=bias_types)\n",
    "    res = fw.weave(sdd, flows, palette=palette).to_widget(**size, margins=margins).auto_save_svg('output/TopUsers_{}_intermediate.svg'.format(bias))\n",
    "    return sdd, flows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following section defines some helpufl functions and variables for use in post-processing the intermediary sankey\n",
    "diagrams created in the previous step. This includes pre-defining some shapes for identifying media type of users,\n",
    "mapping biases to subfigure titles, getting maps of user to different svg elements, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some helper functions for post processing our intermediary svg\n",
    "media_type_to_shape = {\n",
    "    'independent': '<polygon points=\"-6.959 10.34,-2.099 9.74,0.001 5,2.161 9.74,6.961 10.34,3.481 14,4.321 19.1,0.001 16.7,-4.259 19.1,-3.419 14.06\" stroke=\"black\" stroke-width=\"2\" style=\"fill:rgb(102,102,102)\" transform=\"translate(-200,0)\"/>',  # star\n",
    "    'other': '<polygon points=\"16 13.85641,0 13.85641,8 0\" stroke=\"black\" stroke-width=\"2\" style=\"fill:rgb(102,102,102)\" transform=\"translate(-208,0)\"></polygon>',  # triangle\n",
    "    'media': '<circle cx=\"0\" cy=\"10\" r=\"8\" stroke=\"black\" stroke-width=\"2\" style=\"fill:rgb(102,102,102)\" transform=\"translate(-200,0)\"/>',  # circle\n",
    "    'political': '<rect x=\"0\" y=\"0\" width=\"16\" height=\"16\" stroke=\"black\" stroke-width=\"2\" style=\"fill:rgb(102,102,102)\" transform=\"translate(-208,0)\"/>' # square\n",
    "}\n",
    "\n",
    "bias_to_title = {'lefts': 'Left/left leaning', 'rights': 'Right/right leaning', 'fake_extreme_right': 'Extreme bias right/fake news'}\n",
    "affiliation_map = {'media_2020': 'media', 'media_2016': 'media', 'media_both': 'media',\n",
    "                   'polit_2020': 'political', 'polit_2016': 'political', 'polit_both': 'political',\n",
    "                   'other_2020': 'other', 'other_2016': 'other', 'other_both': 'other',\n",
    "                   'indep_2020': 'independent', 'indep_2016': 'independent', 'indep_both': 'independent'}\n",
    "\n",
    "\n",
    "def get_user_to_node(svg_root):\n",
    "    user_to_node = {}\n",
    "    nodes = svg_root.find_all('g', class_='node')\n",
    "    for node in nodes:\n",
    "        user = node.find_all('text', class_='node-title')[0].string\n",
    "        user_to_node[user] = node\n",
    "    return user_to_node\n",
    "\n",
    "def get_user_to_link(svg_root):\n",
    "    user_to_link = {}\n",
    "    links = svg_root.find_all('g', class_='link')\n",
    "    for link in links:\n",
    "        user = link.title.text.split(' ')[0]\n",
    "        user_to_link[user] = link\n",
    "    return user_to_link\n",
    "\n",
    "\n",
    "def create_user_to_media_type():\n",
    "    with open(os.path.join(USER_MAPS, 'user_map_2016.pkl'), 'rb') as file:\n",
    "        m2016 = pickle.load(file)\n",
    "    with open(os.path.join(USER_MAPS, 'user_map_2020.pkl'), 'rb') as file:\n",
    "        m2020 = pickle.load(file)\n",
    "\n",
    "    # load affiliation map\n",
    "    with open(os.path.join(AFFILIATION, 'infl_affiliation_map.json')) as file:\n",
    "        infl_affiliation = json.load(file)\n",
    "        infl_affiliation = {int(key): val for key, val in infl_affiliation.items()}\n",
    "\n",
    "    with open(os.path.join(AFFILIATION, 'infl_affiliation_map_no_handles.json')) as file:\n",
    "        infl_affiliation_no_handle = json.load(file)\n",
    "        infl_affiliation_no_handle = {int(key): val for key, val in infl_affiliation_no_handle.items()}\n",
    "    \n",
    "    m2016_2020 = {**m2016, **m2020}\n",
    "    user_to_fig_text = {m2016_2020[k]['name']: val for k, val in infl_affiliation.items() if k in m2016_2020}\n",
    "\n",
    "    infl_name_to_affiliation = {m2016_2020[k]['name']: val for k, val in infl_affiliation_no_handle.items() if k in m2016_2020}\n",
    "\n",
    "    user_to_affiliation = {}\n",
    "    for k,v in infl_name_to_affiliation.items():\n",
    "        user_to_affiliation[k] = affiliation_map[v]\n",
    "\n",
    "    return user_to_fig_text, user_to_affiliation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step for each subfigure is to post process it. This step adds the following to the plot:\n",
    "1) Anonymize the user handles as required by journal\n",
    "2) Add icons to indicate which media type each user belonged to\n",
    "3) Add bounding rectangles around groups of users by their 2016 rank. In the intermediary step all users were sorted\n",
    "   by rank, but no visibal indication of rank exists. This step bounds all users of the same rank in a grey rectangle\n",
    "   and then labels the rectangle with the rank obtained in 2016.\n",
    "4) Adds a gradient to the flows of participants who either changed media type from 2016 - 2020 or to indicate that the\n",
    "   media type for a users highest obtained rank in 2016 differed from their highest obtained rank in 2020.\n",
    "   By default, all flow colors are those of the media-type of the highest obtained rank in 2020. This change makes the \n",
    "   color of the flow a gradient from the media type of the highest 2016 rank to the media-type of the highest 2020 rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_intermediary_plot(bias, new_merged):\n",
    "    # load the previously saved intermediary svg file\n",
    "    xml = ET.parse('output/TopUsers_{}_intermediate.svg'.format(bias))\n",
    "    xmlstr = ET.tostring(xml.getroot(), pretty_print=True, encoding='unicode')\n",
    "    mysvg = BeautifulSoup(xmlstr, 'lxml')#.svg.extract()\n",
    "\n",
    "    user_to_fig_text, user_to_media_type = create_user_to_media_type()\n",
    "    user_to_node = get_user_to_node(mysvg)\n",
    "    user_to_link = get_user_to_link(mysvg)\n",
    "    rect_group = BeautifulSoup('<g class=\"node_group\"> </g>', 'lxml').g.extract()\n",
    "\n",
    "    diagram_font_weight = \"bold\"\n",
    "    diagram_font_size = \"18px\"\n",
    "\n",
    "    for rank in np.unique(new_merged.rank_2016_str):\n",
    "        rows_of_concern = new_merged[new_merged.rank_2016_str == rank]\n",
    "        miny = np.inf\n",
    "        maxy = -np.inf\n",
    "        for i, row in rows_of_concern.iterrows():\n",
    "            user = row['user_handle']\n",
    "            \n",
    "            # go into the svg file and find the node with title of user\n",
    "            node = user_to_node[user]\n",
    "            \n",
    "            # modify node to include the symbol for given user\n",
    "            ntext = node.find_all('text', class_='node-title')[0]\n",
    "            ntext.string.replace_with(user_to_fig_text[user])\n",
    "            media_type = user_to_media_type[user]\n",
    "            shape = media_type_to_shape[media_type]\n",
    "            if media_type == 'political':\n",
    "                shape = BeautifulSoup(shape).rect.extract()\n",
    "            elif media_type == 'independent' or media_type == 'other':\n",
    "                shape = BeautifulSoup(shape).polygon.extract()\n",
    "            elif media_type == 'media':\n",
    "                shape = BeautifulSoup(shape).circle.extract()\n",
    "\n",
    "            node.append(shape)\n",
    "\n",
    "            # get the translate values\n",
    "            node_transform = node['transform'].replace(')', '')\n",
    "            x, y = node_transform.split('(')[1].split(',')\n",
    "            x = float(x)\n",
    "            y = float(y)\n",
    "\n",
    "            # set the y position of our new rectangle to the y value\n",
    "            if y < miny:\n",
    "                miny = y\n",
    "            if y > maxy:\n",
    "                maxy = y\n",
    "            \n",
    "            # modify color gradient for link *note we do this because some users changed media type from 2016 to 2020,\n",
    "            # like CNN, the gradient changes from center to left leaning to indicate this.\n",
    "            link = user_to_link[user]\n",
    "            bias_2016 = row['bias_2016']\n",
    "            bias_2020 = row['bias_2020']\n",
    "            color_2016 = palette[bias_2016]\n",
    "            color_2020 = palette[bias_2020]\n",
    "            id = 'grad_{}'.format(user)\n",
    "            gradient_xml = '<defs><linearGradient id=\"{}\"><stop offset=\"0%\" stop-color=\"{}\"/><stop offset=\"100%\" stop-color=\"{}\" /></linearGradient></defs>'.format(\n",
    "                id, color_2016, color_2020\n",
    "            )\n",
    "            gradient = BeautifulSoup(gradient_xml, 'lxml').defs.extract()\n",
    "            link.insert(0, gradient)\n",
    "            del link.path['style']\n",
    "            link.path['fill'] = \"url(#{})\".format(id)\n",
    "\n",
    "        # we now have the y value and the height of the rectangle, we now create it and move on to the next rank\n",
    "        height = maxy - miny + 20\n",
    "\n",
    "        # insert the nodes group, this groups our users by their ranking, adding a box around users of the same rank\n",
    "        # and labelling the box with the shared rank \n",
    "        rank_group = BeautifulSoup('<g class=\"rank_group\" transform=\"translate(-320, {})\"></g>\"'.format(miny), 'lxml').g.extract() #-300\n",
    "        rect_xml = '<rect width=\"320\" height=\"{}\" x=\"0\" y=0 style=\"fill:rgb(236,236,236)\" >'.format(height)\n",
    "        rect = BeautifulSoup(rect_xml).rect.extract()\n",
    "        rank_group.append(rect)\n",
    "        # add a label to the rank group rect that denotes the 2016 rank of the users in the group\n",
    "        label_xml = '<text x=0 y={} font-size=\"{}\" font-weight=\"{}\">{}</text>'.format((height/2)+7, diagram_font_size, \n",
    "                                                                                    diagram_font_weight, rank) \n",
    "        label = BeautifulSoup(label_xml, 'lxml')\n",
    "        label = [x for x in label.descendants][-2]\n",
    "        rank_group.append(label)\n",
    "        rect_group.append(rank_group)\n",
    "        \n",
    "    # insert the rank grouping elements into the sankey graph group\n",
    "    mysvg.find_all('g', class_='sankey')[0].insert(0, rect_group)\n",
    "\n",
    "    # set the node-title text attributes, this will modify the font size and weight for all ranks and users\n",
    "    for ntext in mysvg.find_all('text', class_='node-title'):\n",
    "        ntext['font-size'] = diagram_font_size\n",
    "        ntext['font-weight'] = diagram_font_weight\n",
    "        if ntext.string == '_' or 'rank' in ntext.string:\n",
    "            ntext.string.replace_with('Rank > 50')\n",
    "\n",
    "\n",
    "    # add the header information\n",
    "    text_xml = '<text x=\"{}\" y=\"{}\" text-anchor=\"{}\" font-size=\"{}\">{}</text>'\n",
    "    r2016_xml = text_xml.format('48', '0', 'start', '30px', 'Rank 2016') #3%\n",
    "    user_xml = text_xml.format('360', '0', 'end', '30px', 'User') #\n",
    "    r2020_xml = text_xml.format('1520', '0', 'end', '30px', 'Rank 2020') #95%\n",
    "    title_xml = text_xml.format('800', '-35', 'middle', '45px', bias_to_title[bias]) #50%\n",
    "    header_group = BeautifulSoup('<g class=\"header\" transform=\"translate(0, 100)\">{}{}{}{}</g>'.format(\n",
    "        r2016_xml, user_xml, title_xml, r2020_xml), 'lxml').g.extract()\n",
    "\n",
    "    # add the header information to the svg\n",
    "    mysvg.svg.insert(0, header_group)\n",
    "\n",
    "    # BeautifulSoup is writing the linearGradient tag incorrectly, so we will correct that before saving\n",
    "    out = mysvg.svg.extract().prettify()\n",
    "    out = out.replace(\"lineargradient\", \"linearGradient\")\n",
    "\n",
    "    # save file\n",
    "    with open('output/TopUsers_{}.svg'.format(bias), \"w\") as file:\n",
    "        file.write('<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\" \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">')\n",
    "        file.write(str(out))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will generate the intermediary sankey plots for each of the target bias groupings (lefts, rights, fake_extreme_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot lefts\n",
    "bias = 'lefts'\n",
    "merged, user_by_bias = load_data()\n",
    "top_merged = merged[merged.user_handle.isin(user_by_bias[bias])][['user_handle', 'rank_2016', 'rank_2020', 'bias']]\n",
    "plot_biases = bias_to_plot_biases[bias]\n",
    "new_merged = format_data(top_merged, plot_biases)\n",
    "merged_data = {bias: new_merged}\n",
    "size = dict(width=1600, height=1200)\n",
    "margins = dict(top=0, bottom=0, left=360, right=160)\n",
    "sdd, flows = plot_intermediate_sankey(new_merged, bias)\n",
    "fw.weave(sdd, flows, palette=palette).to_widget(**size, margins=margins).auto_save_svg('output/TopUsers_lefts_intermediate.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot rights\n",
    "bias = 'rights'\n",
    "merged, user_by_bias = load_data()\n",
    "top_merged = merged[merged.user_handle.isin(user_by_bias[bias])][['user_handle', 'rank_2016', 'rank_2020', 'bias']]\n",
    "plot_biases = bias_to_plot_biases[bias]\n",
    "new_merged = format_data(top_merged, plot_biases)\n",
    "merged_data[bias] = new_merged\n",
    "size = dict(width=1600, height=1200)\n",
    "margins = dict(top=0, bottom=0, left=360, right=160)\n",
    "sdd, flows = plot_intermediate_sankey(new_merged, bias)\n",
    "fw.weave(sdd, flows, palette=palette).to_widget(**size, margins=margins).auto_save_svg('output/TopUsers_{}_intermediate.svg'.format(bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot fake_extreme_right\n",
    "bias = 'fake_extreme_right'\n",
    "merged, user_by_bias = load_data()\n",
    "top_merged = merged[merged.user_handle.isin(user_by_bias[bias])][['user_handle', 'rank_2016', 'rank_2020', 'bias']]\n",
    "plot_biases = bias_to_plot_biases[bias]\n",
    "new_merged = format_data(top_merged, plot_biases)\n",
    "merged_data[bias] = new_merged\n",
    "size = dict(width=1600, height=1200)\n",
    "margins = dict(top=0, bottom=0, left=360, right=160)\n",
    "sdd, flows = plot_intermediate_sankey(new_merged, bias)\n",
    "fw.weave(sdd, flows, palette=palette).to_widget(**size, margins=margins).auto_save_svg('output/TopUsers_{}_intermediate.svg'.format(bias))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next post process each of the intermediary plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG, display\n",
    "lefts = post_process_intermediary_plot('lefts', merged_data['lefts'])\n",
    "SVG(lefts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rights = post_process_intermediary_plot('rights', merged_data['rights'])\n",
    "SVG(rights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_er = post_process_intermediary_plot('fake_extreme_right', merged_data['fake_extreme_right'])\n",
    "SVG(fake_er)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import svg_stack as ss\n",
    "doc = ss.Document()\n",
    "layout1 = ss.HBoxLayout()\n",
    "layout1.addSVG('output/TopUsers_lefts.svg',alignment=ss.AlignTop|ss.AlignHCenter)\n",
    "layout1.addSVG('output/TopUsers_rights.svg',alignment=ss.AlignCenter)\n",
    "\n",
    "layout2 = ss.VBoxLayout()\n",
    "layout2.addLayout(layout1)\n",
    "layout2.addSVG('output/TopUsers_fake_extreme_right.svg',alignment=ss.AlignCenter)\n",
    "\n",
    "doc.setLayout(layout2)\n",
    "doc.save('output/figure_4_no_legend.svg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our last step is to add the legends to the svg file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icon_legend_xml = '<g class=\"icon_legend\" transform=\"translate(300, 1200)\">\\\n",
    "    <rect height=\"180\" style=\"fill:rgb(236,236,236)\" width=\"450\" x=\"0\" y=\"0\"></rect>\\\n",
    "    <text font-size=\"30px\" text-anchor=\"start\" x=\"0\" y=\"30\">Icon Legend</text>\\\n",
    "    <circle cx=\"0\" cy=\"10\" r=\"8\" stroke=\"black\" stroke-width=\"2\" style=\"fill:rgb(102,102,102)\" transform=\"translate(18,46)\"/>\\\n",
    "    <text font-size=\"24px\" text-anchor=\"start\" x=\"50\" y=\"62\">Linked to media organization</text>\\\n",
    "    <rect x=\"0\" y=\"0\" width=\"16\" height=\"16\" stroke=\"black\" stroke-width=\"2\" style=\"fill:rgb(102,102,102)\" transform=\"translate(10,78)\"/>\\\n",
    "    <text font-size=\"24px\" text-anchor=\"start\" x=\"50\" y=\"94\">Linked to political organization</text>\\\n",
    "    <polygon points=\"-6.959 10.34,-2.099 9.74,0.001 5,2.161 9.74,6.961 10.34,3.481 14,4.321 19.1,0.001 16.7,-4.259 19.1,-3.419 14.06\" stroke=\"black\" stroke-width=\"2\" style=\"fill:rgb(102,102,102)\" transform=\"translate(18,107.5)\"/>\\\n",
    "    <text font-size=\"24px\" text-anchor=\"start\" x=\"50\" y=\"126\">Independent</text>\\\n",
    "    <polygon points=\"16 13.85641,0 13.85641,8 0\" stroke=\"black\" stroke-width=\"2\" style=\"fill:rgb(102,102,102)\" transform=\"translate(10,142)\"></polygon>\\\n",
    "    <text font-size=\"24px\" text-anchor=\"start\" x=\"50\" y=\"158\">Other</text>\\\n",
    "    </g>'\n",
    "\n",
    "color_legend_xml = '<g class=\"color_legend\" transform=\"translate(2450, 1200)\">\\\n",
    "    <rect height=\"280\" style=\"fill:rgb(236,236,236)\" width=\"300\" x=\"0\" y=\"0\"></rect>\\\n",
    "    <text font-size=\"30px\" text-anchor=\"start\" x=\"0\" y=\"30\">Colour Legend</text>\\\n",
    "    <rect x=\"0\" y=\"0\" width=\"16\" height=\"16\" stroke=\"black\" stroke-width=\"2\" fill=\"{}\" transform=\"translate(10,46)\"/>\\\n",
    "    <text font-size=\"24px\" text-anchor=\"start\" x=\"50\" y=\"62\">Left</text>\\\n",
    "    <rect x=\"0\" y=\"0\" width=\"16\" height=\"16\" stroke=\"black\" stroke-width=\"2\" fill=\"{}\" transform=\"translate(10,78)\"/>\\\n",
    "    <text font-size=\"24px\" text-anchor=\"start\" x=\"50\" y=\"94\">Left leaning</text>\\\n",
    "    <rect x=\"0\" y=\"0\" width=\"16\" height=\"16\" stroke=\"black\" stroke-width=\"2\" fill=\"{}\" transform=\"translate(10,110)\"/>\\\n",
    "    <text font-size=\"24px\" text-anchor=\"start\" x=\"50\" y=\"126\">Center</text>\\\n",
    "    <rect x=\"0\" y=\"0\" width=\"16\" height=\"16\" stroke=\"black\" stroke-width=\"2\" fill=\"{}\" transform=\"translate(10,142)\"/>\\\n",
    "    <text font-size=\"24px\" text-anchor=\"start\" x=\"50\" y=\"158\">Right leaning</text>\\\n",
    "    <rect x=\"0\" y=\"0\" width=\"16\" height=\"16\" stroke=\"black\" stroke-width=\"2\" fill=\"{}\" transform=\"translate(10,174)\"/>\\\n",
    "    <text font-size=\"24px\" text-anchor=\"start\" x=\"50\" y=\"190\">Right</text>\\\n",
    "    <rect x=\"0\" y=\"0\" width=\"16\" height=\"16\" stroke=\"black\" stroke-width=\"2\" fill=\"{}\" transform=\"translate(10,206)\"/>\\\n",
    "    <text font-size=\"24px\" text-anchor=\"start\" x=\"50\" y=\"222\">Extreme bias right</text>\\\n",
    "    <rect x=\"0\" y=\"0\" width=\"16\" height=\"16\" stroke=\"black\" stroke-width=\"2\" fill=\"{}\" transform=\"translate(10,238)\"/>\\\n",
    "    <text font-size=\"24px\" text-anchor=\"start\" x=\"50\" y=\"254\">Fake news</text>\\\n",
    "    </g>'.format(*[palette[x] for x in ['left', 'left leaning', 'center', 'right leaning', 'right', 'right extreme', 'fake']])\n",
    "\n",
    "xml = ET.parse('output/figure_4_no_legend.svg')\n",
    "xmlstr = ET.tostring(xml.getroot(), pretty_print=True, encoding='unicode')\n",
    "mysvg = BeautifulSoup(xmlstr, 'xml')\n",
    "\n",
    "color_legend = BeautifulSoup(color_legend_xml).g.extract()\n",
    "mysvg.svg.insert(0, color_legend)\n",
    "\n",
    "\n",
    "icon_legend = BeautifulSoup(icon_legend_xml).g.extract()\n",
    "mysvg.svg.insert(0, icon_legend)\n",
    "\n",
    "\n",
    "\n",
    "with open('output/figure_4.svg', \"w\") as file:\n",
    "    #file.write('<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\" \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">')\n",
    "    file.write(mysvg.prettify())\n",
    "\n",
    "SVG(mysvg.prettify())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
