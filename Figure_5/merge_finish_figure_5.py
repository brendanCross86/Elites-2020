import svg_stack as ss
import lxml.etree as ET
from bs4 import BeautifulSoup
import numpy as np
import pickle
import json
from collections import defaultdict
import cairosvg
from os.path import join
from os import makedirs
import string


RETWEET_GRAPH_JSON_PATH = lambda x: '../data/urls/{}/retweet_graphs_to_draw/retweet_graph_top_combined_topnum30.json'.format(x)
TOPNUM = 30

palette = {'right': '#8F100B', 'lean_right': '#DB4742', 'center': '#CFDB00', 'lean_left': '#4495DB',
           'left': '#0E538F', 'far_left': '#082E4F', 'far_right': '#4F0906', 'fake': '#282828', 'prev_rank': '#7F00DB', 'index': 'green'}
biases = ['far_left', 'left', 'lean_left', 'center', 'lean_right', 'right', 'far_right', 'fake'] 
exclude_bias = ['far_left']

bias_to_label = {'far_left': 'Extreme bias left', 'left': 'Left', 'lean_left': 'Left leaning', 'center': 'Centre', 
                 'lean_right': 'Right leaning', 'right': 'Right', 'far_right': 'Extreme bias right', 'fake': 'Fake news'}

# SAVE_DIR is where we will save the intermediaries and final figure
SAVE_DIR = './output'
makedirs(join(SAVE_DIR), exist_ok=True)

# NETWORK_DIR is the directory that contains the 2016 and 2020 subplots generated by plot_figure_5_<year>.py scripts
NETWORK_DIR = './output'
USER_MAPS = '../data/maps/'
AFFILIATION = '../data/affiliations'

ANONYMIZED = True
affiliation_map = {'media_2020': 'media', 'media_2016': 'media', 'media_both': 'media',
                   'polit_2020': 'political', 'polit_2016': 'political', 'polit_both': 'political',
                   'other_2020': 'other', 'other_2016': 'other', 'other_both': 'other',
                   'indep_2020': 'independent', 'indep_2016': 'independent', 'indep_both': 'independent'}

def assign_color(tag):
    if tag == 'fake':
        return '#282828'
    elif tag == 'extreme_bias_right' or tag == 'far_right':
        return '#4F0906'
    elif tag  == 'right':
        return '#8F100B'
    elif tag == 'lean_right':
        return '#DB4742'
    elif tag == 'center':
        return '#CFDB00'
    elif tag == 'lean_left':
        return '#4495DB'
    elif tag == 'left':
        return '#0E538F'
    elif tag == 'extreme_bias_left' or tag == 'far_left':
        return '#082E4F'
    else:
        print('ERROR incorrect tag:', tag)
    return


def create_user_to_media_type():
    with open(join(USER_MAPS, 'user_map_2016.pkl'), 'rb') as file:
        m2016 = pickle.load(file)
    with open(join(USER_MAPS, 'user_map_2020.pkl'), 'rb') as file:
        m2020 = pickle.load(file)

    # load affiliation map
    with open(join(AFFILIATION, 'infl_affiliation_map.json')) as file:
        infl_affiliation = json.load(file)
        infl_affiliation = {int(key): val for key, val in infl_affiliation.items()}

    with open(join(AFFILIATION, 'infl_affiliation_map_no_handles.json')) as file:
        infl_affiliation_no_handle = json.load(file)
        infl_affiliation_no_handle = {int(key): val for key, val in infl_affiliation_no_handle.items()}
    
    m2016_2020 = {**m2016, **m2020}
    user_to_fig_text = {m2016_2020[k]['name']: val for k, val in infl_affiliation.items() if k in m2016_2020}

    infl_name_to_affiliation = {m2016_2020[k]['name']: val for k, val in infl_affiliation_no_handle.items() if k in m2016_2020}

    user_to_affiliation = {}
    for k,v in infl_name_to_affiliation.items():
        user_to_affiliation[k] = affiliation_map[v]

    return user_to_fig_text, user_to_affiliation


def read_node_data(exclude_biases, year, top_n=5):
    # NOTE: the retweet graph json includes the top N users for a given year by the user's Collective Influence score. 
    #       Each user is given a value per bias of 1 - N, where N indicates the highest CI for that bias and 1 indicates the lowest CI.
    #       In our figure we are going to display rankings from 1-5 where 1 is the best, so we need to map 30 -> 1, 29 -> 2, etc.
    #       I'm fairly certain this was an artifact of trying to plot a particular figure and now we have to live with it.
    node_info = json.load(open(RETWEET_GRAPH_JSON_PATH(year)))

    top_n_to_rank = {TOPNUM - i: i+1 for i in range(TOPNUM)}

    category_list = ['far_left', 'left', 'lean_left', 'center', 'lean_right', 'right', 'far_right', 'fake']
    # remove excluded biases
    category_list = [x for x in category_list if x not in exclude_biases]

    node_dict = {}
    top5s = defaultdict(dict)

    user_id_map = {}
    for item in node_info['nodes']:
        user_id = item['userid']
        username = item['username']
        rank = item['CIoutrank']


        if rank > 25: #25
            continue

        user_id_map[user_id] = username
        labels = []
        branks = {}
        # the 'proportions' property defines for each media bias type a ranking of 1 - N, where 1 is the weakest CI of the 
        # top N and N is the strongest CI.
        for alignment in item['proportions']:
            category = alignment['group']
            if category in exclude_biases:
                continue

            labels.append(category)
            # this value can be 1 - top_num. 1 is the lowest value, indicating the lowest rank user in the top n users.
            # we want to present ranks as 1 - 5 where 1 is the best, so we will reverse this odd 'value' ranking.
            bias_rank = top_n_to_rank[alignment['value']]
            branks[category] = bias_rank

            if bias_rank <= 5:
                top5s[category][bias_rank] = (user_id, username)

        if len(labels) == 0:
            continue

        node_dict[user_id] = {'username': username, 'bias_ranks': branks}

    return node_dict, top5s


def create_user_index(topn_dict):
    i = 1
    user_to_index = {}
    for bias in biases:
        for rank, (user_id, username) in sorted(topn_dict[bias].items(), key=lambda x: x[0]):
            if rank > 25: #25
                continue
            
            if user_id not in user_to_index:
                user_to_index[user_id] = i 
                i += 1

    return user_to_index


def gen_rank_legend(year='2016', minx=0, miny=0):
    # exclude all aliases
    excludes = set(['far_left'])
    user_dict, top5s = read_node_data(excludes, year, 5)
    
    if year == '2020':
        node_dict_2016, top5s_2016 = read_node_data(excludes, '2016')

    # map users to their index in the figure legend
    user_to_index = create_user_index(top5s)
    user_to_anonymized_label, user_to_affiliation = create_user_to_media_type()

    bias_rankings = BeautifulSoup(
        '<g class="bias_rankings" transform="translate({}, {})"></g>"'.format(minx, miny), 'lxml').g.extract()

    # svg grouping for particular network subfigure = "id0:id0" or "id1:id1" for 2016 / 2020 respectively

    current_offset = np.array((0.,0.))
    user_offset_step = np.array((0, 20)) # tune until it looks nice
    bias_offset_step = np.array((0, 30))
    for bias in biases:
        if bias in exclude_bias:
            continue

        local_offset = np.array((0.,0.))

        rank_group = BeautifulSoup(
            '<g class="rank_group" transform="translate({}, {})"></g>"'.format(current_offset[0], current_offset[1]), 'lxml').g.extract()
        
        # add the bias group label
        rank_group.append(BeautifulSoup('<text x="0" y="{}" font-family="Arial" text-weight="bold" font-size="22px" >{}</text>'.format(
            local_offset[1], bias_to_label[bias]), 'xml'))
        
        current_offset += user_offset_step
        local_offset += user_offset_step
        # add the top 5 to group
        for rank, (user_id, username) in sorted(top5s[bias].items(), key=lambda x: x[0]):
            text_element = BeautifulSoup('<text x="0" y="{}" font-size="18px" font-family="Arial"> </text>'.format(local_offset[1]), 'xml')
            text_element = [x for x in text_element.descendants][0]

            username_no_at = username.replace('@', '')
            if username_no_at in user_to_anonymized_label:
                anonymized_text = user_to_anonymized_label[username_no_at]
                anonymized_text = anonymized_text if '@' in anonymized_text else string.capwords(anonymized_text)
            else:
                anonymized_text = '???'
            figtext = username if ANONYMIZED == False else anonymized_text
            rank_user_tspan = BeautifulSoup('<tspan x="0" fill="{}">{} {}</tspan>'.format(palette[bias], rank, figtext), 'xml')

            
            index_offset = "-45" if year == '2020' else "-5"
            index_superscript = BeautifulSoup('<tspan font-weight="bold" text-anchor="end" x="{}" fill="{}">{}</tspan>'.format(index_offset, palette['index'], user_to_index[user_id]), 'xml')
            text_element.append(index_superscript)

            if year == '2020':
                if user_id in node_dict_2016:
                    uname = node_dict_2016[user_id]['username']
                    user_2016_ranks = node_dict_2016[user_id]['bias_ranks']

                    if bias in user_2016_ranks:
                        prev_rank = user_2016_ranks[bias]
                        previous_rank = BeautifulSoup('<tspan font-weight="bold" text-anchor="end" x="-7" fill="{}">({})</tspan>'.format(palette['prev_rank'], prev_rank), 'xml')
                        text_element.append(previous_rank)

            text_element.append(rank_user_tspan)
            
            first = True
            # display superscript ranks in sorted order, sorted on rank 1 -> 5 then media type left -> right
            for b, r in sorted(user_dict[user_id]['bias_ranks'].items(), key=lambda x: (x[1], biases.index(x[0]))):
                if r <= 5 and b != bias:
                    rstr = str(r) if first else ',{}'.format(r)
                    dy = '-5' if first else '0'
                    superscript_tspan = BeautifulSoup('<tspan dy="{}"  font-size="12px" font-family="Arial" fill="{}">{}</tspan>'.format(dy, palette[b], rstr), 'xml')
                    first = False
                    text_element.append(superscript_tspan)
            

            rank_group.append(text_element)
            current_offset += user_offset_step
            local_offset += user_offset_step

        bias_rankings.append(rank_group)
        current_offset += bias_offset_step

    return bias_rankings



# Step 1) Merge the 2016 and 2020 similarity networks into a single side by side figure
doc = ss.Document()
layout1 = ss.HBoxLayout()
layout1.addSVG(join(NETWORK_DIR, 'figure5_community_network_2016.svg'),alignment=ss.AlignTop|ss.AlignHCenter)
layout1.addSVG(join(NETWORK_DIR, 'figure5_community_network_2020.svg'),alignment=ss.AlignCenter)
doc.setLayout(layout1)

# save this intermediary for further processing
outfile = join(SAVE_DIR, 'figure_5_no_legend.svg')
doc.save(outfile)

# Scale the original merged
scale = 4

# Convert and resize the SVG
cairosvg.svg2svg(
    url=outfile,
    write_to=join(SAVE_DIR, 'figure_5_rescaled.svg'),
    scale=scale
)


# reload the resized svg
xml = ET.parse(join(SAVE_DIR, 'figure_5_rescaled.svg'))
xmlstr = ET.tostring(xml.getroot(), pretty_print=True, encoding='unicode')
mysvg = BeautifulSoup(xmlstr, 'xml')

# create a group for the plot elements
plotsvg = mysvg.svg
translate = (180,80)
new_wrapper = mysvg.new_tag("g", **{"class": "wrapper", "transform": "translate({},{})".format(translate[0], translate[1])})
new_wrapper.extend(plotsvg.contents)

# Clear the parent and insert the new wrapper
plotsvg.clear()
plotsvg.append(new_wrapper)

# modify the width and height by the translate amount
width = plotsvg['width']
height = plotsvg['height']

plotsvg['width'] = str(float(plotsvg['width']) + (translate[0] * 3))
plotsvg['height'] = str(float(plotsvg['height']) + (translate[1] * 3))

# modify viewbox accordingly
viewbox = plotsvg['viewBox'].split(' ')
viewbox[-1] = str(float(viewbox[-1]) + (translate[1] * 3))
viewbox[-2] = str(float(viewbox[-2]) + (translate[0] * 3))
plotsvg['viewBox'] = ' '.join(viewbox)


# add the 2016 user rank legend on the left
legend_2016 = gen_rank_legend('2016', 40, 50)
legend_2020 = gen_rank_legend('2020', float(width) + translate[0] + 40, 50)

plotsvg.append(legend_2016)
plotsvg.append(legend_2020)


# add the 2020 user rank legend on the right
with open('output/figure_5.svg', "w") as file:
    #file.write('<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">')
    file.write(str(mysvg.prettify()))


