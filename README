This readme will cover how to generate figure 4. We will also cover how to generate the intermediary data consumed by this script.

Generating Figure 4:
    1) Optionally create a python virtual environment to install the necessary python packages: python -m venv <PATH/TO/VIRTUAL/ENVIRONMENT>
        a) Start your virtual environment: source <PATH/TO/VIRTUAL/ENVIRONMENT>/bin/activate
    2) Install required python packages: pip install -r requirements.txt
        a) Also install jupyter if you don't have it. *Note older version of jupyter may require you to manually enable ipywidgets, see: https://ipywidgets.readthedocs.io/en/8.1.3/user_install.html
    3) Start up a Jupyter notebook: jupyter notebook
    4) Run all cells of the generate_figure_4.ipynb

Note:
The script will need to be pointed at where the required data files are, by default it expects them in ../data/maps, ../data/influencers, ../data/affilliations


Generating Figure 5:
    Notes: Found this in James' /home/flamij2/elites2/analysis/polarization_analysis/figure3 directory
           also, the code generates both networks separately. We can do what we did in figure 4, svg side by side them and then add the code from my full influencer retweet network diagram
    1) analyze_retweet_networks.py
        a) Run for years 2016 and 2020 by setting the 'year' variable to either '2016' or '2020'. 
        b) be sure to modify locations

    2) draw_combined_retweet_graphs.py
        a) Run for 2016 and 2020 by setting year variable.
        b) point save_dir to where the outputs from analyze_retweet_networks live and point network_dir to where the outputs of compute_CI_retweet_networks live.
        /urls/<year>/influencer_rankings_<year>.pickle, /graphs/<year>/<bias>_

    3) get_top_100_unweighted_influencers.py
        a) Run for year = 2016 and year = 2020 (in script)
        b) set target_dir to point towards your <bias>_<year>_ci.gt graphs, generated by Collective_Influence compute_CI_retweet_networks.py

    4) get_similarity_matrix_2016.py
        a) point influencer_dir to the directory containing the top_100 influencer pickle files generated in the previous step.
        b) point raw_retweets_2016 to the 2016 election data sqlite database.
        c) modify the save_dir
        
    5) get_similarity_matrix_2020.py
        a) point influencer_dir to the directory containing the top_100 influencer pickle files generated in the previous step.
        b) point raw_retweets_2016 to the 2016 election data sqlite database.
        c) modify the save_dir

    6) plot_figure_5_2016.py
        a) point SIM_NETWORK_PATH to the similarity network created in get_similarity_matrix_2016.py
        b) point RETWEET_GRAPH_JSON_PATH to the json file created by the draw_combined_retweet_graphs.py method in step 2.
        c) modify the SAVE_DIR to where you want the output

    7) plot_figure_5_2020.py
        a) point SIM_NETWORK_PATH to the similarity network created in get_similarity_matrix_2020.py 
        b) point RETWEET_GRAPH_JSON_PATH to the json file created by the draw_combined_retweet_graphs.py method in step 2.
        c) modify the SAVE_DIR to where you want the output

    8) merge_finish_figure_5.py
        a) This is a convenience script to recreate the manual steps of putting both pdf files side by side and adding a legend.
        b) point this script to the generated pdfs of the previous step
        c) 

# additional packages steps 4,5
Installing collected packages: llvmlite, numba
Successfully installed llvmlite-0.43.0 numba-0.60.0


Generating Figure 3:
    Notes: Found this in /home/flamij2/elites2/analysis/user_analysis
           I am going to provide the script to generate and then the link_map.pkl and missing_users.pkl files as input data. I will ask Alex about providing the code to create link maps
           Link maps, as a reminder, are a mapping of the id number of a twitter account and their twitter url to access their page.
    

Generating from raw data:
This section covers how to generate, from raw data, the data files used by this script.

Install required packages
    1) pip install -r requirements.txt
    2) apt-get install python3-graph-tool


To generate the intermediary files:

    1) Generate retweet network:
        Note: these scripts live in the Retweet_network folder in the OSF repository.
        a) Run generate_retweet_networks.py 
            i) NOTE you need to modify the constants in the script to point to the raw twitter data on your machine. There are also variables on how many threads to use that 
               you may want to tune to your machine. 16 or 32 workers should be fine.
           ii) You will likely need to point the WORKING_DIR variable to a directory with > 50GB
               of disk space. The final step of merging retweet and tweet edges requires the workers have adequet disk space.
          iii) Previously generated versions of these files exist in the Retweet_Network folder of the OSF data repository.
        
        Output: This code will generate the url classified edgelists of the retweet network, for use in CI calculations. Thes files are called: <bias>_retweet_edges.csv, there is one for each bias.
    

    2) Compute Collective Influence:
        Note: these scripts live in the Collective_Influence folder in the OSF repository.
        a) Run setup.py
        b) Run generate_graphs.py
            i) Be sure to set the base_path variable in this script to point at the retweet network edges files generated in step 1.
        c) Run compute_CI_retweet_networks.py
            i) this needs to be run once for each graph generated in the previous step. also expects ../data/ci_output/<graph|output>/2020 directories.
        
        Output: This will produce the <bias>_<year>_ci.gt files used to compute the top_influencer_<bias>.csv files used to make figure 4.


    3) Generate User Mappings:
        Note: the script needed here is the Similarity Matrix folder
        a) Run assemble_user_maps.py
            i) You will need to set target_dir in this script to point at the raw 2020 users.csv files.

        Output: After running this script you will have generated the user_map_2016.pkl and user_map_2020.pkl files.


    4) Find the Top Influencers:
        Note the script you need is in the Retweet_Network directory of the provided code.
        a) Run elites_network_analysis.py
        
        Output: This will generate several files, but the ones we are concerned with are the top_influencers_<bias>.csv files.



Notes:
    1) Since we never provided any requirements.txt it is hard to say which versions of packages were used. I managed to get the code working and have provided all necessary packages in the requirements txt
        i) any additional packages (like graph-tool) that may need to be instaalled in other ways are also listed with the target version